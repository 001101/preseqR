SIZE.INIT = 1 
MU.INIT = 0.5 
tolerance = 1e-10

## x could be a vector
test.logdztnb <- function(x, size, mu)
{
  ## check size and mu bigger than 0
  if (size > 0 && mu > 0)
  {
    ## x > 0 and integer checking
    ## for those x < 1 and x is not an integer, set them to zero first
    x[which(x < 1 | x != floor(x))] = 0
    # calculate the probability
    # y1: log probability of variable equals to zero
    y1 = -size * log(1 + mu / as.double(size))
    # negative binomial coeffiencies
    y2 = lgamma(x + size) - lgamma(x + 1) - lgamma(size)
    # the third terms in your formula see Nature paper
    y3 = x * (log(as.double(mu) / size) - log(1 + as.double(mu) / size))
    # probability of non zero 
    nonzero.prob = 1 - exp(y1)
    # zero truncated negative binomial probability
    y = y1 + y2 + y3 - log(nonzero.prob)
    # set those x < 1 and x non-integer with probability 0
    y[which(x == 0)] = -Inf
    return(y)
}
}

## negative loglikelyhood 
## x is a count vector of a histogram
test.minus.logztnblikelyhood <- function(x, size, mu) 
{
    prob = test.logdztnb(1:length(x), size, mu)
    # minus loglikelyhood
    prob = -prob;
    # negative loglikelyhood
    return( x %*% prob)
}




## MLE
test.zerotruncated.mle <- function(hist, size = SIZE.INIT,
                                      mu = MU.INIT)
{
    if (mode(hist) == 'character') {
        hist.count = read.hist(hist);
    } else {
        hist.count = hist;
    }
    total.sample = (1:length(hist.count) %*% hist.count);
    distinct.sample = sum(hist.count);
    f <- function(x) test.minus.logztnblikelyhood(hist.count,
                                                  size = x[1], mu = x[2]);
    # build-in function to find general minimum
    return(optim(c(size, mu), f, NULL, method = "L-BFGS-B",
                lower = c(0.0001, 0.0001), upper = c(10000, 10000)))
}



## negative loglikelyhood 
## x is a count vector of a histogram
## the ith coordinate corresponds to number of disinct items, each of which
## has ocurrences of i - 1 times
## the first one coordinate corresponds to estimated number of unobserved 
## distinct items
test.minus.log.nbinom.likelyhood <- function(x, size, mu) 
{
    prob = dnbinom(0:(length(x) - 1), size = size, mu = mu, log = TRUE)
    # minus loglikelyhood
    prob = -prob;
    # negative loglikelyhood
    return( x %*% prob)
}




## MLE
test.nbinom.mle <- function(hist, size = SIZE.INIT,
                                      mu = MU.INIT)
{
    if (mode(hist) == 'character') {
        hist.count = read.hist(hist);
    } else {
        hist.count = hist;
    }
    f <- function(x) test.minus.log.nbinom.likelyhood(hist.count,
                                                  size = x[1], mu = x[2]);
    # build-in function to find general minimum
    return(optim(c(size, mu), f, NULL, method = "L-BFGS-B",
                lower = c(0.0001, 0.0001), upper = c(10000, 10000)))
}

## EM
## unobserved item count should not be included in hist
test.nbinom.em <- function(hist, size = SIZE.INIT, mu = MU.INIT)
{
    if (mode(hist) == 'character') {
        hist.count = read.hist(hist);
    } else {
        hist.count = hist;
    }
	# setting the number of unobserved items as 0
	zero.prob = exp(dnbinom(0, size = SIZE.INIT, mu = MU.INIT, log = TRUE))
	# estimate the total number of distinct items
	L = observed.items / (1 - zero.prob)
	# expected the number of unobservations
	zero.items = L * zero.prob
	# setting the inital histogram  
	hist.count = c(zero.items, hist.count);
	# make sure each item in histogram is an integer
	hist.count = as.integer(hist.count)
	loglikelyhood = -1;
	res <- test.nbinom.mle(hist.count, SIZE.INIT, MU.INIT);
	iter = 1
	print(sprintf("item %d value %f", iter, res$value))
	while (abs(res$value - loglikelyhood) > tolerance)
	{
		# update minus loglikelyhood
		loglikelyhood = res$value;
		# estimated the total number of distinct items and
		# expected number of unabserved items
		# the total number of observed items
		observed.items = sum(hist.count[-1])
		# the probility an item unobserved
		zero.prob = exp(dnbinom(0, size = res$par[1], mu = res$par[2], log = TRUE))
		# estimate the total number of distinct items
		L = observed.items / (1 - zero.prob)
		# expected the number of unobservations
		zero.items = L * zero.prob
		# update histogram
		hist.count[1] = zero.items
		hist.count = as.integer(hist.count)
		# re-estimate the parameters
		res <- test.nbinom.mle(hist.count, size = res$par[1], mu = res$par[2])
		iter <- iter + 1
		print(sprintf("item %d value %f", iter, res$value))
	}
	return(res)
}

